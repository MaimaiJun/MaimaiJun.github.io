<!DOCTYPE html>

<html lang="zh-Hans">

<head>
  
  <meta name="baidu-site-verification" content="code-J1Qg17G6wT" />
  <title>TensorFlow 模型训练遇到的问题汇总 - 唛唛君</title>
  <meta charset="UTF-8">
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
  
  

    <!-- Site Verification -->
    <meta name="baidu-site-verification" content="code-J1Qg17G6wT" />

  <link rel="shortcut icon" href="/images//background/head.jpg" type="image/png" />
  <meta name="description" content="🧡某机器人大赛针对比赛的技术分享，总结通用tensorflow遇到的问题🧡">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow 模型训练遇到的问题汇总">
<meta property="og:url" content="http://example.com/2022/11/05/TensorFlow%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%AD%E7%9A%84%E6%B1%87%E6%80%BB/index.html">
<meta property="og:site_name" content="唛唛君">
<meta property="og:description" content="🧡某机器人大赛针对比赛的技术分享，总结通用tensorflow遇到的问题🧡">
<meta property="og:locale">
<meta property="og:image" content="https://img-blog.csdnimg.cn/547d4c6a98364c5882a45735ecc1cefc.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/3f5aa3b1b4624724bae99c7ddec681d4.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/3550745734864dfaa8b4c26029687022.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/3d7aaa9f59db4a69b4893630128c189f.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/dbb7386a7cf5490385a3719d8f6030f9.png">
<meta property="article:published_time" content="2022-11-05T12:05:55.000Z">
<meta property="article:modified_time" content="2022-11-05T08:14:42.405Z">
<meta property="article:author" content="Maimaijun">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="神经网络">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/547d4c6a98364c5882a45735ecc1cefc.png">
  <link rel="stylesheet" href="https://unpkg.com/highlight.js@9.15.8/styles/atom-one-dark.css" crossorigin>
  <link rel="stylesheet" href="/lib/mdui_043tiny/css/mdui.css">
  <link rel="stylesheet" href="/lib/iconfont/iconfont.css">
  <link rel="stylesheet" href="/lib/fancybox/css/jquery.fancybox.min.css">
  <link rel="stylesheet" href="https://unpkg.com/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css">
  
    <link rel="stylesheet" href="//at.alicdn.com/t/font_2421060_8z08qcz5sq3.css">
  
  <link rel="stylesheet" href="/css/style.css?v=1667637105949">
<meta name="generator" content="Hexo 6.2.0"></head>

<body class="mdui-drawer-body-left">
  
  <div id="nexmoe-background">
    <div class="nexmoe-bg" style="background-image: url(/images/background/xiang.jpg)"></div>
    <div class="nexmoe-small" style="background-image: url(/images/background/background.jpg)"></div>
    <div class="mdui-appbar mdui-shadow-0">
      <div class="mdui-toolbar">
        <a mdui-drawer="{target: '#drawer', swipe: true}" title="menu" class="mdui-btn mdui-btn-icon mdui-ripple"><i class="mdui-icon nexmoefont icon-menu"></i></a>
        <div class="mdui-toolbar-spacer"></div>
        <!--<a href="javascript:;" class="mdui-btn mdui-btn-icon"><i class="mdui-icon material-icons">search</i></a>-->
        <a href="/" title="Maimaijun" class="mdui-btn mdui-btn-icon"><img src="/images//background/head.jpg" alt="Maimaijun"></a>
       </div>
    </div>
  </div>
  <div id="nexmoe-header">
      <div class="nexmoe-drawer mdui-drawer" id="drawer">
    <div class="nexmoe-avatar mdui-ripple">
        <a href="/" title="Maimaijun">
            <img src="/images//background/head.jpg" alt="Maimaijun" alt="Maimaijun">
        </a>
    </div>
    <div class="nexmoe-count">
        <div class="nexmoe-count-item"><span>文章</span>3 <div class="item-radius"></div><div class="item-radius item-right"></div> </div>
        <div class="nexmoe-count-item"><span>标签</span>4<div class="item-radius"></div><div class="item-radius item-right"></div></div>
        <div class="nexmoe-count-item"><span>分类</span>0<div class="item-radius"></div><div class="item-radius item-right"></div></div>
    </div>
    <div class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}">
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/" title="回到首页">
            <i class="mdui-list-item-icon nexmoefont icon-meishi"></i>
            <div class="mdui-list-item-content">
                回到首页
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/archives.html" title="文章归档">
            <i class="mdui-list-item-icon nexmoefont icon-hanbao1"></i>
            <div class="mdui-list-item-content">
                文章归档
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/about.html" title="关于我">
            <i class="mdui-list-item-icon nexmoefont icon-jiubei1"></i>
            <div class="mdui-list-item-content">
                关于我
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/friend.html" title="我的朋友">
            <i class="mdui-list-item-icon nexmoefont icon-cola"></i>
            <div class="mdui-list-item-content">
                我的朋友
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/download.html" title="下载中心">
            <i class="mdui-list-item-icon nexmoefont icon-tangguo"></i>
            <div class="mdui-list-item-content">
                下载中心
            </div>
        </a>
        
    </div>
    <aside id="nexmoe-sidebar">
  
  
<!-- 站内搜索 -->

<div class="nexmoe-widget-wrap">
    <div class="nexmoe-widget nexmoe-search" >
        <form id="search-form">
            <label><input type="text" id="local-search-input" name="q" results="0" placeholder="站内搜索" class="input form-control" autocomplete="off" autocorrect="off"/></label>
            <!-- 清空/重置搜索框 -->
            <i class="fa fa-times" onclick="resetSearch()"></i>
        </form>
    </div>
    <div id="local-search-result"></div> <!-- 搜索结果区 -->
    <!-- <p class='no-result'></p> 无匹配时显示，注意在 CSS 中设置默认隐藏 -->
</div>


  
  <div class="nexmoe-widget-wrap">
    <div class="nexmoe-widget nexmoe-social">
        <a class="mdui-ripple" href="https://blog.csdn.net/qq_62096941" target="_blank" mdui-tooltip="{content: 'CSDN'}" style="color: rgb(199,29,35);background-color: rgba(199,29,35,.1);">
            <i class="nexmoefont icon-csdn"></i>
        </a><a class="mdui-ripple" href="https://github.com/MaimaiJun/" target="_blank" mdui-tooltip="{content: 'GitHub'}" style="color: rgb(25, 23, 23);background-color: rgba(25, 23, 23, .15);">
            <i class="nexmoefont icon-github"></i>
        </a>
    </div>
</div>
  
  

  
  
  <div class="nexmoe-widget-wrap">
    <div id="randomtagcloud" class="nexmoe-widget tagcloud nexmoe-rainbow">
      <a href="/tags/EPS32/" style="font-size: 10px;">EPS32</a> <a href="/tags/%E5%8D%95%E7%89%87%E6%9C%BA/" style="font-size: 10px;">单片机</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">神经网络</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" style="font-size: 10px;">计算机视觉</a>
    </div>
    
  </div>

  
  
  <div class="nexmoe-widget-wrap">
    <h3 class="nexmoe-widget-title">文章归档</h3>
    <div class="nexmoe-widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>


<style>
.nexmoe-widget .archive-list-count{
	position : absolute;
	right: 15px;
	top:9px;
	color: #DDD;
}
</style>

  
</aside>
    <div class="nexmoe-copyright">
        &copy; 2022 Maimaijun
        Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
        & <a href="https://github.com/MaimaiJun" target="_blank">唛唛君</a><br/>
        <a href="http://beian.miit.gov.cn" target="_blank">尚未备案</a><br/>
        
        <div style="font-size: 12px">
            <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            本站总访问量  <a id="busuanzi_value_site_pv"></a> 次<br />
            本站访客数<a id="busuanzi_value_site_uv"></a>人次
        </div>
        
        
    </div>

</div><!-- .nexmoe-drawer -->

  </div>
  <div id="nexmoe-content">
    <div class="nexmoe-primary">
        <div class="nexmoe-post">
    
        <div class="nexmoe-post-cover" style="padding-bottom: 24.615384615384617%;">
            <img data-src="/images/blogvip/gaoda.jpg" data-sizes="auto" alt="TensorFlow 模型训练遇到的问题汇总" class="lazyload">
            <h1>TensorFlow 模型训练遇到的问题汇总</h1>
        </div>
    

        <div class="nexmoe-post-meta nexmoe-rainbow" style="margin:10px 0!important;">
    <a><i class="nexmoefont icon-calendar-fill"></i>2022年11月05日</a>
    <a><i class="nexmoefont icon-areachart"></i>3.7k 字</a>
    <a><i class="nexmoefont icon-time-circle-fill"></i>大概 20 分钟</a>
</div>

        <div class="nexmoe-post-right">
            
                <div class="nexmoe-fixed">
                    <div class="nexmoe-valign">
                        <div class="nexmoe-toc">
                            
                            
                                <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#TensorFlow-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB"><span class="toc-number">1.</span> <span class="toc-text">TensorFlow 模型训练遇到的问题汇总</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%A6%82%E4%BD%95%E7%94%A8TensorFlow%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number"></span> <span class="toc-text">一、如何用TensorFlow训练模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81TensorFlow%E6%8A%A5%E9%94%99%E5%A4%84%E7%90%86"><span class="toc-number"></span> <span class="toc-text">二、TensorFlow报错处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%97%A0%E6%B3%95from-object-detection-import-XXX"><span class="toc-number">1.</span> <span class="toc-text">1.无法from object_detection import XXX</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%89%BE%E4%B8%8D%E5%88%B0string-int-label-map-pb2-py%E6%96%87%E4%BB%B6%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">2.找不到string_int_label_map_pb2.py文件怎么办？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%B2%A1%E6%9C%89officaial%E6%88%96%E8%80%85%E6%97%A0%E6%B3%95import-officaial%E5%A6%82%E4%BD%95%E5%81%9A%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">3.没有officaial或者无法import officaial如何做？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2"><span class="toc-number"></span> <span class="toc-text">三、如何优雅地进行模型转换</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81TF2-x%E7%9A%84%E6%B5%8B%E8%AF%95"><span class="toc-number">1.</span> <span class="toc-text">一、TF2.x的测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-tf1-x%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B5%8B%E8%AF%95"><span class="toc-number">2.</span> <span class="toc-text">二.tf1.x模型的测试</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number"></span> <span class="toc-text">总结</span></a>
                            
                        </div>
                    </div>
                </div>
            
        </div>

        <article>
            <p>🧡某机器人大赛针对比赛的技术分享，总结通用tensorflow遇到的问题🧡</p>
<span id="more"></span>


<h2 id="TensorFlow-模型训练遇到的问题汇总"><a href="#TensorFlow-模型训练遇到的问题汇总" class="headerlink" title="TensorFlow 模型训练遇到的问题汇总"></a>TensorFlow 模型训练遇到的问题汇总</h2><p>@<a href="%E6%96%87%E7%AB%A0%E7%9B%AE%E5%BD%95">TOC</a></p>
<hr>
<p>🕓问题汇总并解决时间为2022年10-11月，所使用TensorFlow版本为tf1.13-gpu版本和tf2.6(pip install直接安装版本）</p>
<hr>
<p><code>以下是本篇文章分享的内容，下面案例可供参考</code></p>
<h1 id="一、如何用TensorFlow训练模型"><a href="#一、如何用TensorFlow训练模型" class="headerlink" title="一、如何用TensorFlow训练模型"></a>一、如何用TensorFlow训练模型</h1><p><strong>1、环境配置</strong>🍉<br> <strong>TF2.x</strong>  ： 与TF1.x安装方法相同，只是tensorflow的版本不相同<br>    <a target="_blank" rel="noopener" href="https://76clk5mi.fast-github.ml/-----https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">TF2.x API文件</a></p>
<p>  <strong>TF1.x  ：</strong><br>       1️⃣在anaconda上创建一个虚拟环境    conda create -n your_name python&#x3D;3.6<br>       2️⃣激活进入虚拟环境                           activate ssd            #win10系统下，自己创建的虚拟环境<br>       3️⃣根据硬件安装                                  conda install tensorflow-gpu&#x3D;&#x3D;1.13.1 或者 tensorflow1.13.1<br>       4️⃣下载Tesorflow Object Detecttion API 的 r1.13.0 版本 并在虚拟环境下编译安装<br>（版本不对应可能会导致模型训练转换出错）<br>      <a target="_blank" rel="noopener" href="https://github.com/HelloSZS/models-r1.13.0">TF1.x API(以前版本，copy其他博主）</a><br><strong>2.数据集收集和制作</strong>🍉<br>     将所需要识别物体的图片收集若干张(仅用作测试训练整个流程大概100张就有明显的效果了），通过数据标注工具对图片进行标注，通常用的打标工具为labelImg，可以通过pip install labelImg下载安装，具体使用方法不详细说明。<br>     博主本人用的是网站在线标注(make-sense),标注完后可以选择输出自己喜欢的格式(但是需要注意不同训练代码对xml文件的读取问题，make-sense标注一般没有目标的详细参数，只有矩形框的参数）<br>     <img data-fancybox="gallery" data-sizes="auto" data-src="https://img-blog.csdnimg.cn/547d4c6a98364c5882a45735ecc1cefc.png" alt="在这里插入图片描述" class="lazyload"><br>       <strong>3、Xml做分类</strong>🍉<br>              将训练的xml文件分为训练集、验证集和测试集。</p>
<pre><code class="python">import os  
import random  
import time  
import shutil

xmlfilepath=r&#39;./your_dataset&#39;  
saveBasePath=r&quot;./Annotations&quot;

trainval_percent=0.8  
train_percent=0.8  
total_xml = os.listdir(xmlfilepath)  
num=len(total_xml)  
list=range(num)  
tv=int(num*trainval_percent)  
tr=int(tv*train_percent)  
trainval= random.sample(list,tv)  
train=random.sample(trainval,tr)  
print(&quot;train and val size&quot;,tv)  
print(&quot;train size&quot;,tr) 

start = time.time()

test_num=0  
val_num=0  
train_num=0  

for i in list:  
    name=total_xml[i]
    if i in trainval:  #train and val set 
        if i in train: 
            directory=&quot;train&quot;  
            train_num += 1  
            xml_path = os.path.join(os.getcwd(), &#39;Annotations/&#123;&#125;&#39;.format(directory))  
            if(not os.path.exists(xml_path)):  
                os.mkdir(xml_path)  
            filePath=os.path.join(xmlfilepath,name)  
            newfile=os.path.join(saveBasePath,os.path.join(directory,name))  
            shutil.copyfile(filePath, newfile)
        else:
            directory=&quot;validation&quot;  
            xml_path = os.path.join(os.getcwd(), &#39;Annotations/&#123;&#125;&#39;.format(directory))  
            if(not os.path.exists(xml_path)):  
                os.mkdir(xml_path)  
            val_num += 1  
            filePath=os.path.join(xmlfilepath,name)   
            newfile=os.path.join(saveBasePath,os.path.join(directory,name))  
            shutil.copyfile(filePath, newfile)

    else:
        directory=&quot;test&quot;  
        xml_path = os.path.join(os.getcwd(), &#39;Annotations/&#123;&#125;&#39;.format(directory))  
        if(not os.path.exists(xml_path)):  
                os.mkdir(xml_path)  
        test_num += 1  
        filePath=os.path.join(xmlfilepath,name)  
        newfile=os.path.join(saveBasePath,os.path.join(directory,name))  
        shutil.copyfile(filePath, newfile)

end = time.time()  
seconds=end-start  
print(&quot;train total : &quot;+str(train_num))  
print(&quot;validation total : &quot;+str(val_num))  
print(&quot;test total : &quot;+str(test_num))  
total_num=train_num+val_num+test_num  
print(&quot;total number : &quot;+str(total_num))  
print( &quot;Time taken : &#123;0&#125; seconds&quot;.format(seconds))
</code></pre>
<p>   <strong>4、Xml转换csv文件</strong>🍉</p>
<pre><code class="python">import os  
import glob  
import pandas as pd  
import xml.etree.ElementTree as ET 

def xml_to_csv(path):  
    xml_list = []  
    for xml_file in glob.glob(path + &#39;/*.xml&#39;):  
        tree = ET.parse(xml_file)  
        root = tree.getroot()
        
        print(root.find(&#39;filename&#39;).text)  
        for member in root.findall(&#39;object&#39;): 
            value = (root.find(&#39;filename&#39;).text,  
                int(root.find(&#39;size&#39;)[0].text),   #width  
                int(root.find(&#39;size&#39;)[1].text),   #height  
                member[0].text,  
                int(member[4][0].text),  
                int(float(member[4][1].text)),  
                int(member[4][2].text),  
                int(member[4][3].text)  
                )  
            xml_list.append(value)
    column_name = [&#39;filename&#39;, &#39;width&#39;, &#39;height&#39;, &#39;class&#39;, &#39;xmin&#39;, &#39;ymin&#39;, &#39;xmax&#39;, &#39;ymax&#39;]
    xml_df = pd.DataFrame(xml_list, columns=column_name)  
    return xml_df      

def main():  
    for directory in [&#39;train&#39;,&#39;test&#39;,&#39;validation&#39;]:  
        xml_path = os.path.join(os.getcwd(), &#39;Annotations/&#123;&#125;&#39;.format(directory))  

        xml_df = xml_to_csv(xml_path)  
        # xml_df.to_csv(&#39;whsyxt.csv&#39;, index=None)  
        xml_df.to_csv(&#39;./your_dataset.csv&#39;.format(directory), index=None)  
        print(&#39;Successfully converted xml to csv.&#39;)

main()
</code></pre>
<p><strong>5、Csv转换Tensorflow训练所用的record文件</strong>🍉</p>
<pre><code class="python"># csv2tfrecord.py

# -*- coding: utf-8 -*-


&quot;&quot;&quot;
Usage:
  # From tensorflow/models/
  # Create train data:
  python  csv2tfrecord.txt --csv_input=train_labels.csv  --output_path=train.record
  # Create test data:
  python csv2tfrecord.py --csv_input=test.csv  --output_path=itest.record
&quot;&quot;&quot;


import os
import io
import pandas as pd
import tensorflow.compat.v1 as tf

from PIL import Image
from object_detection.utils import dataset_util
from collections import namedtuple, OrderedDict

os.chdir(&#39;./test1&#39;)

flags = tf.app.flags
flags.DEFINE_string(&#39;csv_input&#39;, &#39;&#39;, &#39;Path to the CSV input&#39;)
flags.DEFINE_string(&#39;output_path&#39;, &#39;&#39;, &#39;Path to output TFRecord&#39;)
FLAGS = flags.FLAGS


# TO-DO replace this with label map
def class_text_to_int(row_label):   # 根据自己的标签修改
    if row_label == &#39;object&#39;:   
        return 1
    else:
        None


def split(df, group):
    data = namedtuple(&#39;data&#39;, [&#39;filename&#39;, &#39;object&#39;])
    gb = df.groupby(group)
    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]


def create_tf_example(group, path):
    with tf.gfile.GFile(os.path.join(path, &#39;&#123;&#125;&#39;.format(group.filename)), &#39;rb&#39;) as fid:
        encoded_jpg = fid.read()
    encoded_jpg_io = io.BytesIO(encoded_jpg)
    image = Image.open(encoded_jpg_io)
    width, height = image.size

    filename = group.filename.encode(&#39;utf8&#39;)
    image_format = b&#39;jpg&#39;
    xmins = []
    xmaxs = []
    ymins = []
    ymaxs = []
    classes_text = []
    classes = []

    for index, row in group.object.iterrows():
        xmins.append(row[&#39;xmin&#39;] / width)
        xmaxs.append(row[&#39;xmax&#39;] / width)
        ymins.append(row[&#39;ymin&#39;] / height)
        ymaxs.append(row[&#39;ymax&#39;] / height)
        classes_text.append(row[&#39;class&#39;].encode(&#39;utf8&#39;))
        classes.append(class_text_to_int(row[&#39;class&#39;]))

    tf_example = tf.train.Example(features=tf.train.Features(feature=&#123;
        &#39;image/height&#39;: dataset_util.int64_feature(height),
        &#39;image/width&#39;: dataset_util.int64_feature(width),
        &#39;image/filename&#39;: dataset_util.bytes_feature(filename),
        &#39;image/source_id&#39;: dataset_util.bytes_feature(filename),
        &#39;image/encoded&#39;: dataset_util.bytes_feature(encoded_jpg),
        &#39;image/format&#39;: dataset_util.bytes_feature(image_format),
        &#39;image/object/bbox/xmin&#39;: dataset_util.float_list_feature(xmins),
        &#39;image/object/bbox/xmax&#39;: dataset_util.float_list_feature(xmaxs),
        &#39;image/object/bbox/ymin&#39;: dataset_util.float_list_feature(ymins),
        &#39;image/object/bbox/ymax&#39;: dataset_util.float_list_feature(ymaxs),
        &#39;image/object/class/text&#39;: dataset_util.bytes_list_feature(classes_text),
        &#39;image/object/class/label&#39;: dataset_util.int64_list_feature(classes),
    &#125;))
    return tf_example


def main(_):
    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)
    path = os.path.join(os.getcwd(), &#39;./data&#39;)         #  需改动
    examples = pd.read_csv(FLAGS.csv_input)
    grouped = split(examples, &#39;filename&#39;)
    for group in grouped:
        tf_example = create_tf_example(group, path)
        writer.write(tf_example.SerializeToString())

    writer.close()
    output_path = os.path.join(os.getcwd(), FLAGS.output_path)
    print(&#39;Successfully created the TFRecords: &#123;&#125;&#39;.format(output_path))


if __name__ == &#39;__main__&#39;:
    tf.app.run()
</code></pre>
<p>如此上述所需文件已经配置完成，训练所需config自己配置。<br><strong>tensorFlow预训练模型：</strong><br>💡   <a target="_blank" rel="noopener" href="https://76clk5mi.fast-github.ml/-----https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">tf2.预训练模型</a><br>💡    <a target="_blank" rel="noopener" href="https://github.com/HelloSZS/models-r1.13.0/blob/master/research/object_detection/g3doc/detection_model_zoo.md">tf1.预训练模型</a></p>
<h1 id="二、TensorFlow报错处理"><a href="#二、TensorFlow报错处理" class="headerlink" title="二、TensorFlow报错处理"></a>二、TensorFlow报错处理</h1><h2 id="1-无法from-object-detection-import-XXX"><a href="#1-无法from-object-detection-import-XXX" class="headerlink" title="1.无法from object_detection import XXX"></a>1.无法from object_detection import XXX</h2><p> 📦运行训练指令时<strong>model_main_tf2.py</strong>与<strong>object_detection</strong>在同一级目录下，无法正常导入。如何避免非在同一级目录下from XXX import 文件。<br> 在anaconda 的当前环境中，<strong>lib</strong>-&gt;<strong>site_package</strong>-&gt;添加pth文件(文件内包含所需越级访问的路径，经过测试，在计算机path添加没有效果）<br> <strong>PTH</strong>文件内的输入所需要的绝对路径，可以参考如下：</p>
<blockquote>
<p>C:\Users\呆呆兽\Desktop\tensorflow_models\models-master\research<br>C:\Users\呆呆兽\Desktop\tensorflow_models\models-master\research\slim<br>C:\Users\呆呆兽\Desktop\tensorflow_models\models-master\research\object_detection<br>C:\Users\呆呆兽\Desktop\tensorflow_models\models-master\official</p>
</blockquote>
<h2 id="2-找不到string-int-label-map-pb2-py文件怎么办？"><a href="#2-找不到string-int-label-map-pb2-py文件怎么办？" class="headerlink" title="2.找不到string_int_label_map_pb2.py文件怎么办？"></a>2.找不到string_int_label_map_pb2.py文件怎么办？</h2><blockquote>
<p>“protoc.exe” object_detection&#x2F;protos&#x2F;*.proto –python_out&#x3D;.</p>
</blockquote>
<p>📦将<strong>object_detection&#x2F;protoc</strong> 内的py文件编译</p>
<blockquote>
<p>还有可能出现错误：<br>      <strong>cannot import name ‘builder’ from ‘google.protobuf.internal’</strong></p>
</blockquote>
<p>📦解决：<a target="_blank" rel="noopener" href="https://github.com/protocolbuffers/protobuf/issues/9778">https://github.com/protocolbuffers/protobuf/issues/9778</a><br>  更换个与本机pip库 相匹配的protoc，例如本机版本为3.19.1，不能使用protoc_3.20版本</p>
<h2 id="3-没有officaial或者无法import-officaial如何做？"><a href="#3-没有officaial或者无法import-officaial如何做？" class="headerlink" title="3.没有officaial或者无法import officaial如何做？"></a>3.没有officaial或者无法import officaial如何做？</h2><blockquote>
<p>错误做法：把与reasearch同一级的offical复制<br>正确做法： <strong>pip install tf-models-official</strong><br>安装中途可能遇到的错误： pip install pypiwin32 提示Cannot uninstall ‘pywin32’<br><strong>site_package中直接删除pywin32文件夹，或则删除pywin32-220-py3.6.egg-info</strong></p>
</blockquote>
<h1 id="三、如何优雅地进行模型转换"><a href="#三、如何优雅地进行模型转换" class="headerlink" title="三、如何优雅地进行模型转换"></a>三、如何优雅地进行模型转换</h1><p>🎈🎈经过上述两步骤，tensorflow API的环境应该可以运行了🎈🎈</p>
<h2 id="一、TF2-x的测试"><a href="#一、TF2-x的测试" class="headerlink" title="一、TF2.x的测试"></a>一、TF2.x的测试</h2><pre><code class="bash">TF2.x 训练指令
️🎈模型训练：
python object_detection/model_main_tf2.py --model_dir=log --pipeline_config_path=log/ssd_mobilenet_v2_320x320_coco17_tpu-8.config --alsologtostderr
️🎈模型导出(原始模型）：
python exporter_main_v2.py --input_type=image_tensor --pipeline_config_path=log/ssd_mobilenet_v2_320x320_coco17_tpu-8.config --trained_checkpoint_dir=log/ --output_directory=log/eval：
</code></pre>
<p><strong>Saved_model模型验证：</strong>🍊</p>
<pre><code class="python"># coding: utf-8
 
import os
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39;    # Suppress TensorFlow logging (1)
import pathlib
import tensorflow as tf
import cv2
import argparse
 
tf.get_logger().setLevel(&#39;ERROR&#39;)           # Suppress TensorFlow logging (2)
 
parser = argparse.ArgumentParser()
parser.add_argument(&#39;--model&#39;, help=&#39;Folder that the Saved Model is Located In&#39;,
                    default=&#39;log/eval/eval&#39;)
parser.add_argument(&#39;--labels&#39;, help=&#39;Where the Labelmap is Located&#39;,
                    default=&#39;tag_label_map.pbtxt&#39;)
parser.add_argument(&#39;--image&#39;, help=&#39;Name of the single image to perform detection on&#39;,
                    default=&#39;00028.jpg&#39;)
parser.add_argument(&#39;--threshold&#39;, help=&#39;Minimum confidence threshold for displaying detected objects&#39;,
                    default=0.5)
#home/models-master/research/object_detection/image/JPEGImages/00004.jpg                    
args = parser.parse_args()
# Enable GPU dynamic memory allocation
gpus = tf.config.experimental.list_physical_devices(&#39;GPU&#39;)
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)
 
# PROVIDE PATH TO IMAGE DIRECTORY
IMAGE_PATHS = args.image
 
 
# PROVIDE PATH TO MODEL DIRECTORY
PATH_TO_MODEL_DIR = args.model
 
# PROVIDE PATH TO LABEL MAP
PATH_TO_LABELS = args.labels
 
# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD
MIN_CONF_THRESH = float(args.threshold)
 
# LOAD THE MODEL
 
import time
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils
 
PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + &quot;/saved_model&quot;
 
print(&#39;Loading model...&#39;, end=&#39;&#39;)
start_time = time.time()
 
# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION
detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)
 
end_time = time.time()
elapsed_time = end_time - start_time
print(&#39;Done! Took &#123;&#125; seconds&#39;.format(elapsed_time))
 
# LOAD LABEL MAP DATA FOR PLOTTING
 
category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,
                                                                    use_display_name=True)
 
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings(&#39;ignore&#39;)   # Suppress Matplotlib warnings
 
def load_image_into_numpy_array(path):
    &quot;&quot;&quot;Load an image from file into a numpy array.
 
    Puts image into numpy array to feed into tensorflow graph.
    Note that by convention we put it into a numpy array with shape
    (height, width, channels), where channels=3 for RGB.
 
    Args:
      path: the file path to the image
 
    Returns:
      uint8 numpy array with shape (img_height, img_width, 3)
    &quot;&quot;&quot;
    return np.array(Image.open(path))
 
print(&#39;Running inference for &#123;&#125;... &#39;.format(IMAGE_PATHS), end=&#39;&#39;)
image = cv2.imread(IMAGE_PATHS)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image_expanded = np.expand_dims(image_rgb, axis=0)
# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
input_tensor = tf.convert_to_tensor(image)
# The model expects a batch of images, so add an axis with `tf.newaxis`.
input_tensor = input_tensor[tf.newaxis, ...]
 
# input_tensor = np.expand_dims(image_np, 0)
t1=time.time()
detections = detect_fn(input_tensor)
t2=time.time()
print(t2-t1)
 
 
 
# All outputs are batches tensors.
# Convert to numpy arrays, and take index [0] to remove the batch dimension.
# We&#39;re only interested in the first num_detections.
num_detections = int(detections.pop(&#39;num_detections&#39;))
detections = &#123;key: value[0, :num_detections].numpy()
               for key, value in detections.items()&#125;
detections[&#39;num_detections&#39;] = num_detections
 
# detection_classes should be ints.
detections[&#39;detection_classes&#39;] = detections[&#39;detection_classes&#39;].astype(np.int64)
 
image_with_detections = image.copy()
 
# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS
viz_utils.visualize_boxes_and_labels_on_image_array(
      image_with_detections,
      detections[&#39;detection_boxes&#39;],
      detections[&#39;detection_classes&#39;],
      detections[&#39;detection_scores&#39;],
      category_index,
      use_normalized_coordinates=True,
      max_boxes_to_draw=100,
      min_score_thresh=MIN_CONF_THRESH,
      agnostic_mode=False)
 
 
print(&#39;\n&#39; + &#39;Done&#39;)
# DISPLAYS OUTPUT IMAGE
#if image_with_detections.shape[0]&gt;1000:
    #image_with_detections = cv2.resize(image_with_detections,[int(0.5*image_with_detections.shape[0]),[int(0.5*image_with_detections.shape[1]]))
#cv2.imwrite(&quot;pic/&quot;+IMAGE_PATHS.split(&quot;/&quot;)[-1],image_with_detections)
#cv2.imwrite(&quot;test.jpg&quot;,image_with_detections)
cv2.imshow(&#39;Object Detector&#39;, image_with_detections)
#cv2.resizeWindow(&quot;Object Detector&quot;, 720,1280)
 
 
# CLOSES WINDOW ONCE KEY IS PRESSED
cv2.waitKey(0)
# CLEANUP
cv2.destroyAllWindows()
</code></pre>
<p>看看验证效果：🍊<br><img data-fancybox="gallery" data-sizes="auto" data-src="https://img-blog.csdnimg.cn/3f5aa3b1b4624724bae99c7ddec681d4.png" alt="在这里插入图片描述" class="lazyload"><br><strong>未知能否成功的冻结：</strong><br>为了减少模型大小，还可以强行将save_model进行冻结（<del>冻结代码仅供参考，还未完全验证）</del> </p>
<pre><code class="python">import tensorflow as tf
from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2

# 模型path
pb_file_path = &#39;./log/eval/eval/saved_model&#39;
# 图片path
image_path = &#39;./00028.jpg&#39;

# 定义输入格式
img = tf.io.read_file(image_path)
img = tf.image.decode_jpeg(img, channels=3)  # shape=(450, 600, 3)
img = tf.image.resize(img, (300, 300))
img = tf.expand_dims(img, axis=0) #  shape=(1, 450, 600, 3)
img=tf.cast(img,dtype=tf.uint8)

# 加载模型
network = tf.saved_model.load(pb_file_path)
#奇怪的模型输出加载方式不同，若是keral则tf.keras.models.load_model
# Convert Keras model to ConcreteFunction
full_model = tf.function(lambda x: network(x))

full_model = full_model.get_concrete_function(
tf.TensorSpec(img.shape, img.dtype)) 

# Get frozen ConcreteFunction
frozen_func = convert_variables_to_constants_v2(full_model)
frozen_func.graph.as_graph_def()

layers = [op.name for op in frozen_func.graph.get_operations()]
print(&quot;-&quot; * 50)
print(&quot;Frozen model layers: &quot;)
for layer in layers:
    print(layer)

print(&quot;-&quot; * 50)
print(&quot;Frozen model inputs: &quot;)
print(frozen_func.inputs)
print(&quot;Frozen model outputs: &quot;)
print(frozen_func.outputs)

# Save frozen graph from frozen ConcreteFunction to hard drive
tf.io.write_graph(graph_or_graph_def=frozen_func.graph,
        logdir=&quot;./frozen_models&quot;,
        name=&quot;frozen_graph.pb&quot;,
        as_text=False)
</code></pre>
<h2 id="二-tf1-x模型的测试"><a href="#二-tf1-x模型的测试" class="headerlink" title="二.tf1.x模型的测试"></a>二.tf1.x模型的测试</h2><pre><code class="bash">TF1.x 训练指令
️🎈模型训练：
python object_detection/legacy/train.py --logtostderr --train_dir=training/ --pipeline_config_path=ssd_mobilenet_v2_coco.config
️🎈模型导出(冻结图）：
python object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path ssd_mobilenet_v2_coco.config --trained_checkpoint_prefix training/model.ckpt-6000 --output_directory inference_graph
</code></pre>
<p><strong>验证frozen.pb文件：🍊</strong></p>
<pre><code class="python">import numpy as np
import os
import glob
import tensorflow as tf
import time
from distutils.version import StrictVersion
import matplotlib
from matplotlib import pyplot as plt
from PIL import Image
import keras
import tensorflow as tf
 
from object_detection.utils import ops as utils_ops
 
from object_detection.utils import label_map_util
 
from object_detection.utils import visualization_utils as vis_util

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
keras.backend.tensorflow_backend.set_session(tf.Session(config=config))
# 防止backend=&#39;Agg&#39;导致不显示图像的情况
#os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;-1&quot;        #CPU
matplotlib.use(&#39;TkAgg&#39;)
 
if StrictVersion(tf.__version__) &lt; StrictVersion(&#39;1.12.0&#39;):
    raise ImportError(&#39;Please upgrade your TensorFlow installation to v1.12.*.&#39;)
 
MODEL_NAME = &#39;inference_graph&#39;
 
# Path to frozen detection graph. This is the actual model that is used for the object detection.
PATH_TO_FROZEN_GRAPH = MODEL_NAME + &#39;/frozen_inference_graph.pb&#39;
 
# List of the strings that is used to add correct label for each box.
PATH_TO_LABELS = &#39;tag_label_map.pbtxt&#39;
 
detection_graph = tf.Graph()
with detection_graph.as_default():
    od_graph_def = tf.GraphDef()
    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, &#39;rb&#39;) as fid:
        serialized_graph = fid.read()
        od_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(od_graph_def, name=&#39;&#39;)
 
category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)
 
def load_image_into_numpy_array(image):
    im_width, im_height = image.size
    return np.array(image.getdata()).reshape(
        (im_height, im_width, 3)).astype(np.uint8)
 

PATH_TO_TEST_IMAGES_DIR = &#39;00001.jpg&#39;
TEST_IMAGE_PATHS = glob.glob(PATH_TO_TEST_IMAGES_DIR)
 
# Size, in inches, of the output images.
IMAGE_SIZE = (12, 8)
 
def run_inference_for_single_image(image, graph):
    with graph.as_default():
        with tf.Session() as sess:
            # Get handles to input and output tensors
            ops = tf.get_default_graph().get_operations()
            all_tensor_names = &#123;output.name for op in ops for output in op.outputs&#125;
            tensor_dict = &#123;&#125;
            for key in [
                &#39;num_detections&#39;, &#39;detection_boxes&#39;, &#39;detection_scores&#39;,
                &#39;detection_classes&#39;, &#39;detection_masks&#39;
            ]:
                tensor_name = key + &#39;:0&#39;
                if tensor_name in all_tensor_names:
                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(
                        tensor_name)
            if &#39;detection_masks&#39; in tensor_dict:
                # The following processing is only for single image
                detection_boxes = tf.squeeze(tensor_dict[&#39;detection_boxes&#39;], [0])
                detection_masks = tf.squeeze(tensor_dict[&#39;detection_masks&#39;], [0])
                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.
                real_num_detection = tf.cast(tensor_dict[&#39;num_detections&#39;][0], tf.int32)
                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])
                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])
                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
                    detection_masks, detection_boxes, image.shape[1], image.shape[2])
                detection_masks_reframed = tf.cast(
                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)
                # Follow the convention by adding back the batch dimension
                tensor_dict[&#39;detection_masks&#39;] = tf.expand_dims(
                    detection_masks_reframed, 0)
            image_tensor = tf.get_default_graph().get_tensor_by_name(&#39;image_tensor:0&#39;)
 
            # Run inference
            output_dict = sess.run(tensor_dict,
                                   feed_dict=&#123;image_tensor: image&#125;)
 
            # all outputs are float32 numpy arrays, so convert types as appropriate
            output_dict[&#39;num_detections&#39;] = int(output_dict[&#39;num_detections&#39;][0])
            output_dict[&#39;detection_classes&#39;] = output_dict[
                &#39;detection_classes&#39;][0].astype(np.int64)
            output_dict[&#39;detection_boxes&#39;] = output_dict[&#39;detection_boxes&#39;][0]
            output_dict[&#39;detection_scores&#39;] = output_dict[&#39;detection_scores&#39;][0]
            if &#39;detection_masks&#39; in output_dict:
                output_dict[&#39;detection_masks&#39;] = output_dict[&#39;detection_masks&#39;][0]
    return output_dict
 
for image_path in TEST_IMAGE_PATHS:
    image = Image.open(image_path)
    start = time.time()
    # the array based representation of the image will be used later in order to prepare the
    # result image with boxes and labels on it.
    image_np = load_image_into_numpy_array(image)
    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
    image_np_expanded = np.expand_dims(image_np, axis=0)
    # Actual detection.
    output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)
    # Visualization of the results of a detection.
    vis_util.visualize_boxes_and_labels_on_image_array(
        image_np,
        output_dict[&#39;detection_boxes&#39;],
        output_dict[&#39;detection_classes&#39;],
        output_dict[&#39;detection_scores&#39;],
        category_index,
        instance_masks=output_dict.get(&#39;detection_masks&#39;),
        use_normalized_coordinates=True,
        line_thickness=5)
    print(&quot;class:&quot;,output_dict[&#39;detection_classes&#39;])
    print(&quot;score:&quot;,output_dict[&#39;detection_scores&#39;])
    end = time.time()
    print(&quot;internel:&quot;,end-start)
    plt.figure(figsize=IMAGE_SIZE)
    plt.imshow(image_np)
    plt.show()
</code></pre>
<p><strong>看看效果</strong>：<br>     <img data-fancybox="gallery" data-sizes="auto" data-src="https://img-blog.csdnimg.cn/3550745734864dfaa8b4c26029687022.png" alt="在这里插入图片描述" class="lazyload"><br>     <strong>pb模型转换ir模型：</strong>🍊</p>
<p>需要自己安装Openvino在电脑上(运行代码前已经成功激活）</p>
<pre><code class="go">自定义模型转换ir 测试大概限于tf1.x
python mo_tf.py --input_model frozen_graph.pb --tensorflow_use_custom_operations_config extensions/front/tf/ssd_v2_support.json  --tensorflow_object_detection_api_pipeline_config pipeline.config --data_type FP16
</code></pre>
<p><strong>验证一下Openvino 对模型的加速力度</strong>😍<br><img data-fancybox="gallery" data-sizes="auto" data-src="https://img-blog.csdnimg.cn/3d7aaa9f59db4a69b4893630128c189f.png" alt="在这里插入图片描述" class="lazyload"><br><strong>可以看到成功验证🤣！！！</strong></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>💡 💡 💡<br>入手TensorFlow一个星期，每天晚上都在查找各种报错原因，最终才发现TF1.x和TF2.x 新酒不能装旧瓶子的痛苦😫</p>
<p>好在不断坚持下，成功训练出ssd_mobilenetV2_coco的模型，并将其转换为可以intel加速的IR模型，终于把之前没有解决的问题完善了。</p>
<p>希望看到博客的你能够从中成功解决问题，如果有对TF2模型如何冻结优化也可以在评论区交流👍</p>
<p>由于是新人博主，希望能对文章中不对的内容指正！！！<br>💡 💡 💡</p>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://img-blog.csdnimg.cn/dbb7386a7cf5490385a3719d8f6030f9.png" alt="在这里插入图片描述" class="lazyload"></p>

        </article>

        
            
  <div class="nexmoe-post-copyright">
    <strong>本文作者：</strong>Maimaijun<br>
    
    <strong>本文链接：</strong><a href="http://example.com/2022/11/05/TensorFlow%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%AD%E7%9A%84%E6%B1%87%E6%80%BB/" title="http:&#x2F;&#x2F;example.com&#x2F;2022&#x2F;11&#x2F;05&#x2F;TensorFlow%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%AD%E7%9A%84%E6%B1%87%E6%80%BB&#x2F;" target="_blank" rel="noopener">http:&#x2F;&#x2F;example.com&#x2F;2022&#x2F;11&#x2F;05&#x2F;TensorFlow%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%AD%E7%9A%84%E6%B1%87%E6%80%BB&#x2F;</a><br>

    
      <strong>版权声明：</strong>本文采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh" target="_blank">CC BY-NC-SA 3.0 CN</a> 协议进行许可
    
  </div>


        

        <div class="nexmoe-post-meta nexmoe-rainbow">
    
    
        <a class="nexmoefont icon-tag-fill -none-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a> <a class="nexmoefont icon-tag-fill -none-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag">计算机视觉</a>
    
</div>

    <div class="nexmoe-post-footer">
        <section class="nexmoe-comment">
    <div class="valine"></div>
<script src="https://unpkg.com/leancloud-storage/dist/av-min.js"></script>
<script src='https://unpkg.com/valine@1.3.9/dist/Valine.min.js'></script>
<script>
    // 使用方法 https://valine.js.org/quickstart.html
    new Valine({
        el: '.valine',
        appId: 'U6Ugwu9lXMAfB7QD3qeHRFCB-gzGzoHsz',
        appKey: '2IkYYVX5XI95SyfJuaWr05e5'
    })
</script>
</section>
    </div>
</div>


        <div class="nexmoe-post-right">
          
            <div class="nexmoe-fixed">
              <div class="nexmoe-tool">
                <a href="#" aria-label="回到顶部" title="top"><button class="mdui-fab mdui-ripple"><i class="nexmoefont icon-caret-top"></i></button></a>
              </div>
            </div>
          
        </div>
    </div>
  </div>
  <div id="nexmoe-pendant">
    <div class="nexmoe-drawer mdui-drawer nexmoe-pd" id="drawer">
        
            <div class="nexmoe-pd-item">
                <div class="clock">
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="needle" id="hours"></div>
        <div class="needle" id="minutes"></div>
        <div class="needle" id="seconds"></div>
        <div class="clock_logo">

        </div>

    </div>
<style>
    .clock {
        background-color: #ffffff;
        width: 70vw;
        height: 70vw;
        max-width: 70vh;
        max-height: 70vh;
        border: solid 2.8vw #242424;
        position: relative;
        overflow: hidden;
        border-radius: 50%;
        box-sizing: border-box;
        box-shadow: 0 1.4vw 2.8vw rgba(0, 0, 0, 0.8);
        zoom:0.2
    }

    .memory {
        position: absolute;
        top: 50%;
        left: 50%;
        transform-origin: center;
    }

    .memory:nth-child(1) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(0deg) translateY(-520%);
    }

    .memory:nth-child(2) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(6deg) translateY(-1461%);
    }

    .memory:nth-child(3) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(12deg) translateY(-1461%);
    }

    .memory:nth-child(4) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(18deg) translateY(-1461%);
    }

    .memory:nth-child(5) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(24deg) translateY(-1461%);
    }

    .memory:nth-child(6) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(30deg) translateY(-520%);
    }

    .memory:nth-child(7) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(36deg) translateY(-1461%);
    }

    .memory:nth-child(8) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(42deg) translateY(-1461%);
    }

    .memory:nth-child(9) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(48deg) translateY(-1461%);
    }

    .memory:nth-child(10) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(54deg) translateY(-1461%);
    }

    .memory:nth-child(11) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(60deg) translateY(-520%);
    }

    .memory:nth-child(12) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(66deg) translateY(-1461%);
    }

    .memory:nth-child(13) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(72deg) translateY(-1461%);
    }

    .memory:nth-child(14) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(78deg) translateY(-1461%);
    }

    .memory:nth-child(15) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(84deg) translateY(-1461%);
    }

    .memory:nth-child(16) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(90deg) translateY(-520%);
    }

    .memory:nth-child(17) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(96deg) translateY(-1461%);
    }

    .memory:nth-child(18) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(102deg) translateY(-1461%);
    }

    .memory:nth-child(19) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(108deg) translateY(-1461%);
    }

    .memory:nth-child(20) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(114deg) translateY(-1461%);
    }

    .memory:nth-child(21) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(120deg) translateY(-520%);
    }

    .memory:nth-child(22) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(126deg) translateY(-1461%);
    }

    .memory:nth-child(23) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(132deg) translateY(-1461%);
    }

    .memory:nth-child(24) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(138deg) translateY(-1461%);
    }

    .memory:nth-child(25) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(144deg) translateY(-1461%);
    }

    .memory:nth-child(26) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(150deg) translateY(-520%);
    }

    .memory:nth-child(27) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(156deg) translateY(-1461%);
    }

    .memory:nth-child(28) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(162deg) translateY(-1461%);
    }

    .memory:nth-child(29) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(168deg) translateY(-1461%);
    }

    .memory:nth-child(30) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(174deg) translateY(-1461%);
    }

    .memory:nth-child(31) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(180deg) translateY(-520%);
    }

    .memory:nth-child(32) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(186deg) translateY(-1461%);
    }

    .memory:nth-child(33) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(192deg) translateY(-1461%);
    }

    .memory:nth-child(34) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(198deg) translateY(-1461%);
    }

    .memory:nth-child(35) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(204deg) translateY(-1461%);
    }

    .memory:nth-child(36) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(210deg) translateY(-520%);
    }

    .memory:nth-child(37) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(216deg) translateY(-1461%);
    }

    .memory:nth-child(38) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(222deg) translateY(-1461%);
    }

    .memory:nth-child(39) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(228deg) translateY(-1461%);
    }

    .memory:nth-child(40) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(234deg) translateY(-1461%);
    }

    .memory:nth-child(41) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(240deg) translateY(-520%);
    }

    .memory:nth-child(42) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(246deg) translateY(-1461%);
    }

    .memory:nth-child(43) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(252deg) translateY(-1461%);
    }

    .memory:nth-child(44) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(258deg) translateY(-1461%);
    }

    .memory:nth-child(45) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(264deg) translateY(-1461%);
    }

    .memory:nth-child(46) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(270deg) translateY(-520%);
    }

    .memory:nth-child(47) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(276deg) translateY(-1461%);
    }

    .memory:nth-child(48) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(282deg) translateY(-1461%);
    }

    .memory:nth-child(49) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(288deg) translateY(-1461%);
    }

    .memory:nth-child(50) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(294deg) translateY(-1461%);
    }

    .memory:nth-child(51) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(300deg) translateY(-520%);
    }

    .memory:nth-child(52) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(306deg) translateY(-1461%);
    }

    .memory:nth-child(53) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(312deg) translateY(-1461%);
    }

    .memory:nth-child(54) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(318deg) translateY(-1461%);
    }

    .memory:nth-child(55) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(324deg) translateY(-1461%);
    }

    .memory:nth-child(56) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(330deg) translateY(-520%);
    }

    .memory:nth-child(57) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(336deg) translateY(-1461%);
    }

    .memory:nth-child(58) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(342deg) translateY(-1461%);
    }

    .memory:nth-child(59) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(348deg) translateY(-1461%);
    }

    .memory:nth-child(60) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(354deg) translateY(-1461%);
    }

    .needle {
        position: absolute;
        top: 50%;
        left: 50%;
        transform-origin: center;
    }

    .needle#hours {
        background-color: #1f1f1f;
        width: 4%;
        height: 30%;
        transform-origin: center 75%;
        transform: translate(-50%, -75%);
    }

    .needle#hours.moving {
        transition: transform 150ms ease-out;
    }

    .needle#hours:after {
        content: '';
        background-color: #1f1f1f;
        width: 4vw;
        height: 4vw;
        max-width: 4vh;
        max-height: 4vh;
        display: block;
        position: absolute;
        top: 75%;
        left: 50%;
        box-sizing: border-box;
        border-radius: 50%;
        transform: translate(-50%, -50%);
    }

    .needle#minutes {
        background-color: #1f1f1f;
        width: 2%;
        height: 45%;
        transform-origin: center 75%;
        transform: translate(-50%, -75%);
    }

    .needle#minutes.moving {
        transition: transform 150ms ease-out;
    }

    .needle#minutes:after {
        content: '';
        background-color: #1f1f1f;
        width: 4vw;
        height: 4vw;
        max-width: 4vh;
        max-height: 4vh;
        display: block;
        position: absolute;
        top: 75%;
        left: 50%;
        box-sizing: border-box;
        border-radius: 50%;
        transform: translate(-50%, -50%);
    }

    .needle#seconds {
        background-color: #cb2f2f;
        width: 1%;
        height: 50%;
        transform-origin: center 75%;
        transform: translate(-50%, -75%);
    }

    .needle#seconds.moving {
        transition: transform 150ms ease-out;
    }

    .needle#seconds:after {
        content: '';
        background-color: #cb2f2f;
        width: 2.5vw;
        height: 2.5vw;
        max-width: 2.5vh;
        max-height: 2.5vh;
        display: block;
        position: absolute;
        top: 75%;
        left: 50%;
        box-sizing: border-box;
        border-radius: 50%;
        transform: translate(-50%, -50%);
    }
    .clock_logo{
        width: 10vw;
        height: 10vw;
        max-width: 10vh;
        max-height: 10vh;
        position: absolute;
        top: 50%;
        left: 50%;
        box-sizing: border-box;
        border-radius: 50%;
        transform: translate(-50%, -50%);
        background-size: 100% 100%;
        background-repeat: no-repeat;
    }
    @media (min-width: 100vh) {
        .clock {
            border: solid 2.8vh #242424;
            box-shadow: 0 1.4vh 2.8vh rgba(0, 0, 0, 0.8);
        }
    }

</style>





            </div>
        
</div>
<style>
    .nexmoe-pd {
        left: auto;
        top: 40px;
        right: 0;
    }
    .nexmoe-pd-item{
       display: flex;
        justify-content: center;
        margin-bottom: 30px;
    }
</style>

  </div>
  <script src="https://unpkg.com/lazysizes@5.1.0/lazysizes.min.js"></script>
<script src="https://cdn.staticfile.org/highlight.js/10.0.0/highlight.min.js"></script>
<script src="https://unpkg.com/mdui@0.4.3/dist/js/mdui.min.js?v=1"></script>

<script>
	hljs.initHighlightingOnLoad();
</script>

<script src="https://unpkg.com/jquery@3.5.1/dist/jquery.slim.min.js"></script>
<script src="/lib/fancybox/js/jquery.fancybox.min.js"></script>


<script src="/js/app.js?v=1667637105950"></script>

<script src="https://unpkg.com/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js"></script>
<script>
	$(".justified-gallery").justifiedGallery({
		rowHeight: 160,
		margins: 10,
	});
</script>

  





<!-- hexo injector body_end start -->
<script src="/js/clock.js"></script>

<script src="https://code.jquery.com/jquery-3.6.0.js"></script>

<script src="/js/search.js"></script>

<script src="https://unpkg.com/clipboard@2.0.8/dist/clipboard.min.js"></script>

<script src="/lib/codeBlock/codeBlockFuction.js"></script>

<script src="/lib/codeBlock/codeLang.js"></script>

<script src="/lib/codeBlock/codeCopy.js"></script>

<script src="/lib/codeBlock/codeShrink.js"></script>

<link rel="stylesheet" href="/lib/codeBlock/matery.css">

<script src="/js/webapp.js"></script>
<!-- hexo injector body_end end --></body>
</html>

<script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/360b395f.js","daovoice")</script>
<script>
  daovoice('init', {
    app_id: "360b395f"
  });
  daovoice('update');
</script>

